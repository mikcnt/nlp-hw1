{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "b3e10353",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-10T13:44:02.975755Z",
     "iopub.status.busy": "2021-04-10T13:44:02.975112Z",
     "iopub.status.idle": "2021-04-10T13:44:03.547413Z",
     "shell.execute_reply": "2021-04-10T13:44:03.546878Z",
     "shell.execute_reply.started": "2021-04-10T13:44:02.975674Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from pprint import pprint\n",
    "import jsonlines\n",
    "import os\n",
    "import re\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "from typing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d6c8defa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-10T08:57:17.284893Z",
     "iopub.status.busy": "2021-04-10T08:57:17.284222Z",
     "iopub.status.idle": "2021-04-10T08:57:17.292296Z",
     "shell.execute_reply": "2021-04-10T08:57:17.290505Z",
     "shell.execute_reply.started": "2021-04-10T08:57:17.284807Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_path = 'data/train.jsonl'\n",
    "dev_path = 'data/dev.jsonl'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4ce6a9",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1ea67e30",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-10T09:41:15.139246Z",
     "iopub.status.busy": "2021-04-10T09:41:15.138963Z",
     "iopub.status.idle": "2021-04-10T09:41:15.144116Z",
     "shell.execute_reply": "2021-04-10T09:41:15.143293Z",
     "shell.execute_reply.started": "2021-04-10T09:41:15.139211Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/49239941/what-is-unk-in-the-pretrained-glove-vector-files-e-g-glove-6b-50d-txt\n",
    "\n",
    "unk_embedding = '0.22418134 -0.28881392 0.13854356 0.00365387 -0.12870757 0.10243822 0.061626635 0.07318011 -0.061350107 -1.3477012 0.42037755 -0.063593924 -0.09683349 0.18086134 0.23704372 0.014126852 0.170096 -1.1491593 0.31497982 0.06622181 0.024687296 0.076693475 0.13851812 0.021302193 -0.06640582 -0.010336159 0.13523154 -0.042144544 -0.11938788 0.006948221 0.13333307 -0.18276379 0.052385733 0.008943111 -0.23957317 0.08500333 -0.006894406 0.0015864656 0.063391194 0.19177166 -0.13113557 -0.11295479 -0.14276934 0.03413971 -0.034278486 -0.051366422 0.18891625 -0.16673574 -0.057783455 0.036823478 0.08078679 0.022949161 0.033298038 0.011784158 0.05643189 -0.042776518 0.011959623 0.011552498 -0.0007971594 0.11300405 -0.031369694 -0.0061559738 -0.009043574 -0.415336 -0.18870236 0.13708843 0.005911723 -0.113035575 -0.030096142 -0.23908928 -0.05354085 -0.044904727 -0.20228513 0.0065645403 -0.09578946 -0.07391877 -0.06487607 0.111740574 -0.048649278 -0.16565254 -0.052037314 -0.078968436 0.13684988 0.0757494 -0.006275573 0.28693774 0.52017444 -0.0877165 -0.33010918 -0.1359622 0.114895485 -0.09744406 0.06269521 0.12118575 -0.08026362 0.35256687 -0.060017522 -0.04889904 -0.06828978 0.088740796 0.003964443 -0.0766291 0.1263925 0.07809314 -0.023164088 -0.5680669 -0.037892066 -0.1350967 -0.11351585 -0.111434504 -0.0905027 0.25174105 -0.14841858 0.034635577 -0.07334565 0.06320108 -0.038343467 -0.05413284 0.042197507 -0.090380974 -0.070528865 -0.009174437 0.009069661 0.1405178 0.02958134 -0.036431845 -0.08625681 0.042951006 0.08230793 0.0903314 -0.12279937 -0.013899368 0.048119213 0.08678239 -0.14450377 -0.04424887 0.018319942 0.015026873 -0.100526 0.06021201 0.74059093 -0.0016333034 -0.24960588 -0.023739101 0.016396184 0.11928964 0.13950661 -0.031624354 -0.01645025 0.14079992 -0.0002824564 -0.08052984 -0.0021310581 -0.025350995 0.086938225 0.14308536 0.17146006 -0.13943303 0.048792403 0.09274929 -0.053167373 0.031103406 0.012354865 0.21057427 0.32618305 0.18015954 -0.15881181 0.15322933 -0.22558987 -0.04200665 0.0084689725 0.038156632 0.15188617 0.13274793 0.113756925 -0.095273495 -0.049490947 -0.10265804 -0.27064866 -0.034567792 -0.018810693 -0.0010360252 0.10340131 0.13883452 0.21131058 -0.01981019 0.1833468 -0.10751636 -0.03128868 0.02518242 0.23232952 0.042052146 0.11731903 -0.15506615 0.0063580726 -0.15429358 0.1511722 0.12745973 0.2576985 -0.25486213 -0.0709463 0.17983761 0.054027 -0.09884228 -0.24595179 -0.093028545 -0.028203879 0.094398156 0.09233813 0.029291354 0.13110267 0.15682974 -0.016919162 0.23927948 -0.1343307 -0.22422817 0.14634751 -0.064993896 0.4703685 -0.027190214 0.06224946 -0.091360025 0.21490277 -0.19562101 -0.10032754 -0.09056772 -0.06203493 -0.18876675 -0.10963594 -0.27734384 0.12616494 -0.02217992 -0.16058226 -0.080475815 0.026953284 0.110732645 0.014894041 0.09416802 0.14299914 -0.1594008 -0.066080004 -0.007995227 -0.11668856 -0.13081996 -0.09237365 0.14741232 0.09180138 0.081735 0.3211204 -0.0036552632 -0.047030564 -0.02311798 0.048961394 0.08669574 -0.06766279 -0.50028914 -0.048515294 0.14144728 -0.032994404 -0.11954345 -0.14929578 -0.2388355 -0.019883996 -0.15917352 -0.052084364 0.2801028 -0.0029121689 -0.054581646 -0.47385484 0.17112483 -0.12066923 -0.042173345 0.1395337 0.26115036 0.012869649 0.009291686 -0.0026459037 -0.075331464 0.017840583 -0.26869613 -0.21820338 -0.17084768 -0.1022808 -0.055290595 0.13513643 0.12362477 -0.10980586 0.13980341 -0.20233242 0.08813751 0.3849736 -0.10653763 -0.06199595 0.028849555 0.03230154 0.023856193 0.069950655 0.19310954 -0.077677034 -0.144811'\n",
    "unk_embedding = unk_embedding.strip().split(' ')\n",
    "unk_embedding = torch.tensor([float(c) for c in unk_embedding])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1cab081c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-10T08:57:17.989985Z",
     "iopub.status.busy": "2021-04-10T08:57:17.989812Z",
     "iopub.status.idle": "2021-04-10T08:57:17.993378Z",
     "shell.execute_reply": "2021-04-10T08:57:17.992798Z",
     "shell.execute_reply.started": "2021-04-10T08:57:17.989964Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_dictionary(dictionary, path):\n",
    "    with open(path, 'wb') as f:\n",
    "        pickle.dump(dictionary, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_dictionary(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de5a2206",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-10T08:57:19.269270Z",
     "iopub.status.busy": "2021-04-10T08:57:19.268782Z",
     "iopub.status.idle": "2021-04-10T08:57:19.278966Z",
     "shell.execute_reply": "2021-04-10T08:57:19.278331Z",
     "shell.execute_reply.started": "2021-04-10T08:57:19.269208Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Saving / loading models\n",
    "class Checkpoint:\n",
    "    def __init__(self, path, resume=False):\n",
    "        self.path = path\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "        self.resume = resume\n",
    "\n",
    "    def load(self, model, optimizer, id_path=\"\"):\n",
    "        if (not self.resume) and id_path == \"\":\n",
    "            raise RuntimeError()\n",
    "        if self.resume:\n",
    "            id_path = sorted(os.listdir(self.path))[-1]\n",
    "        self.checkpoint = torch.load(\n",
    "            os.path.join(self.path, id_path), map_location=lambda storage, loc: storage\n",
    "        )\n",
    "        if self.checkpoint == None:\n",
    "            raise RuntimeError(\"Checkpoint empty.\")\n",
    "        epoch = self.checkpoint[\"epoch\"]\n",
    "        model.load_state_dict(self.checkpoint[\"model_state_dict\"])\n",
    "        optimizer.load_state_dict(self.checkpoint[\"optimizer_state_dict\"])\n",
    "        loss = self.checkpoint[\"loss\"]\n",
    "        return (model, optimizer, epoch, loss)\n",
    "\n",
    "    def save(self, model, optimizer, epoch, loss, accuracy):\n",
    "        model_checkpoint = {\n",
    "            \"model_state_dict\": model.state_dict(),\n",
    "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "            \"epoch\": epoch,\n",
    "            \"loss\": loss,\n",
    "            \"accuracy\": accuracy\n",
    "        }\n",
    "        checkpoint_name = \"{}.pth\".format(str(epoch).zfill(3))\n",
    "        complete_path = os.path.join(self.path, checkpoint_name)\n",
    "        torch.save(model_checkpoint, complete_path)\n",
    "        return checkpoint_name\n",
    "\n",
    "    def load_just_model(self, model, id_path=\"\"):\n",
    "        if self.resume:\n",
    "            id_path = sorted(os.listdir(self.path))[-1]\n",
    "        self.checkpoint = torch.load(\n",
    "            os.path.join(self.path, id_path), map_location=lambda storage, loc: storage\n",
    "        )\n",
    "        if self.checkpoint == None:\n",
    "            raise RuntimeError(\"Checkpoint empty.\")\n",
    "        model.load_state_dict(self.checkpoint[\"model_state_dict\"])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "b7773050",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-10T13:58:11.763745Z",
     "iopub.status.busy": "2021-04-10T13:58:11.763400Z",
     "iopub.status.idle": "2021-04-10T13:58:11.768187Z",
     "shell.execute_reply": "2021-04-10T13:58:11.767633Z",
     "shell.execute_reply.started": "2021-04-10T13:58:11.763702Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess(sentence):\n",
    "    # lowercase sentence\n",
    "    sentence = sentence.lower()\n",
    "    # remove punctuation\n",
    "    # sentence = sentence.translate(str.maketrans('', '', string.punctuation))\n",
    "    sentence = re.sub('[^\\w\\s]', ' ', sentence)\n",
    "    sentence = re.sub(' +', ' ', sentence).strip()\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "8fe5025f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-10T13:56:31.725683Z",
     "iopub.status.busy": "2021-04-10T13:56:31.725225Z",
     "iopub.status.idle": "2021-04-10T13:56:31.732000Z",
     "shell.execute_reply": "2021-04-10T13:56:31.731149Z",
     "shell.execute_reply.started": "2021-04-10T13:56:31.725625Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this lemmatization is what we expected'"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess('this Lemmatization, is! what we expected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fe790114",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-10T09:45:25.809358Z",
     "iopub.status.busy": "2021-04-10T09:45:25.809195Z",
     "iopub.status.idle": "2021-04-10T09:45:25.812097Z",
     "shell.execute_reply": "2021-04-10T09:45:25.811597Z",
     "shell.execute_reply.started": "2021-04-10T09:45:25.809338Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_position(sentence: str, start: int):\n",
    "    return len(re.findall(\" +\", stringa[:start]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec400b4",
   "metadata": {},
   "source": [
    "# Create word embedding with GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d96cbbba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-10T10:46:39.279827Z",
     "iopub.status.busy": "2021-04-10T10:46:39.279653Z",
     "iopub.status.idle": "2021-04-10T10:46:39.283399Z",
     "shell.execute_reply": "2021-04-10T10:46:39.282902Z",
     "shell.execute_reply.started": "2021-04-10T10:46:39.279805Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sentence2vector(sentence: str) -> Optional[torch.Tensor]:\n",
    "    sentences_word_vector = []\n",
    "    for w in re.split(\" +\", sentence):\n",
    "        word_embedding = word_vectors[w] if w in word_vectors else unk_embedding\n",
    "        sentences_word_vector.append(word_embedding)\n",
    "    # sentences_word_vector = [word_vectors[w] for w in re.split(\" +\", sentence) if w in word_vectors]\n",
    "    \n",
    "    if len(sentences_word_vector) == 0:\n",
    "        return None\n",
    "\n",
    "    sentences_word_vector = torch.stack(sentences_word_vector)  # tensor shape: (#words X #features)\n",
    "    return torch.mean(sentences_word_vector, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "6153b842",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-10T13:19:37.859782Z",
     "iopub.status.busy": "2021-04-10T13:19:37.859138Z",
     "iopub.status.idle": "2021-04-10T13:19:37.875242Z",
     "shell.execute_reply": "2021-04-10T13:19:37.874102Z",
     "shell.execute_reply.started": "2021-04-10T13:19:37.859699Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def w_sentence2vector(sentence: str, target_start: int) -> Optional[torch.Tensor]:\n",
    "    # get embedding for each word in the sentence\n",
    "    target_position = find_position(sentence, target_start)\n",
    "    sentences_word_vector = []\n",
    "    for w in re.split(\" +\", sentence):\n",
    "        word_embedding = word_vectors[w] if w in word_vectors else unk_embedding\n",
    "        sentences_word_vector.append(word_embedding)\n",
    "    \n",
    "    sentences_word_vector = torch.stack(sentences_word_vector)\n",
    "    \n",
    "    # weights from 1 to 0\n",
    "    weights = torch.linspace(1, 0.1, len(sentences_word_vector)).unsqueeze(1)\n",
    "    \n",
    "    # weighted vector\n",
    "    new_vectors = sentences_word_vector\n",
    "    \n",
    "    t = target_position\n",
    "    n = len(sentences_word_vector)\n",
    "    # right of the target word\n",
    "    new_vectors[t:] = new_vectors[t:] * weights[:n - t]\n",
    "    # left of the target word\n",
    "    new_vectors[:t] = new_vectors[:t] * reversed(weights[1:t + 1])\n",
    "    \n",
    "    # denominator (sum of the weights)\n",
    "    weights_sum = weights[:n - t].sum() + weights[1:t + 1].sum()\n",
    "\n",
    "    return new_vectors.sum(dim=0) / weights_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3b4e8bd1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-10T08:57:29.469089Z",
     "iopub.status.busy": "2021-04-10T08:57:29.468923Z",
     "iopub.status.idle": "2021-04-10T08:57:29.472031Z",
     "shell.execute_reply": "2021-04-10T08:57:29.471524Z",
     "shell.execute_reply.started": "2021-04-10T08:57:29.469068Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cosine_similarity(v1: torch.Tensor, v2: torch.Tensor) -> float:\n",
    "    num = torch.sum(v1 * v2)\n",
    "    den = torch.linalg.norm(v1) * torch.linalg.norm(v2)\n",
    "    return (num / den).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "c9713d10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-10T13:51:31.157353Z",
     "iopub.status.busy": "2021-04-10T13:51:31.156881Z",
     "iopub.status.idle": "2021-04-10T13:52:03.586129Z",
     "shell.execute_reply": "2021-04-10T13:52:03.585428Z",
     "shell.execute_reply.started": "2021-04-10T13:51:31.157295Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5edeee9b4dc4702acbdb02b0ad1ced8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "word_vectors = dict()\n",
    "n_words = 400_000\n",
    "with open('embeddings/glove.6B.300d.txt') as f:\n",
    "    for i, line in tqdm(enumerate(f), total=n_words):\n",
    "\n",
    "        word, *vector = line.strip().split(' ')\n",
    "        vector = torch.tensor([float(c) for c in vector])\n",
    "        \n",
    "        word_vectors[word] = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "860a00b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-09T13:23:58.035928Z",
     "iopub.status.busy": "2021-04-09T13:23:58.035659Z",
     "iopub.status.idle": "2021-04-09T13:24:17.643624Z",
     "shell.execute_reply": "2021-04-09T13:24:17.643100Z",
     "shell.execute_reply.started": "2021-04-09T13:23:58.035895Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save_dictionary(word_vectors, 'model/vocabulary.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "cb371044",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-10T17:13:24.602861Z",
     "iopub.status.busy": "2021-04-10T17:13:24.602186Z",
     "iopub.status.idle": "2021-04-10T17:13:24.608364Z",
     "shell.execute_reply": "2021-04-10T17:13:24.607877Z",
     "shell.execute_reply.started": "2021-04-10T17:13:24.602777Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PorterStemmer>"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "8c526450",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-10T17:16:48.933455Z",
     "iopub.status.busy": "2021-04-10T17:16:48.933271Z",
     "iopub.status.idle": "2021-04-10T17:16:49.032882Z",
     "shell.execute_reply": "2021-04-10T17:16:49.032383Z",
     "shell.execute_reply.started": "2021-04-10T17:16:48.933437Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "no_emb = []\n",
    "with jsonlines.open(train_path, 'r') as f:\n",
    "    for i, line in enumerate(f.iter()):\n",
    "        start1 = int(line['start1'])\n",
    "        start2 = int(line['start2'])\n",
    "        end1 = int(line['end1'])\n",
    "        end2 = int(line['end2'])\n",
    "        # sentences.append(line['sentence1'])\n",
    "        # sentences.append(line['sentence2'])\n",
    "        s1 = line['sentence1']\n",
    "        s2 = line['sentence2']\n",
    "        lemma1 = s1[start1:end1]\n",
    "        lemma2 = s2[start2:end2]\n",
    "        # if lemma1 != lemma2:\n",
    "        #     print(lemma1, lemma2)\n",
    "        lemma1 = preprocess(lemma1)\n",
    "        lemma2 = preprocess(lemma2)\n",
    "        if lemma1 not in word_vectors:\n",
    "            no_emb.append(lemma1)\n",
    "        # if lemma2 not in word_vectors:\n",
    "        #     no_emb.append(lemma2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "ea456dd7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-10T17:17:55.079530Z",
     "iopub.status.busy": "2021-04-10T17:17:55.078892Z",
     "iopub.status.idle": "2021-04-10T17:17:55.093523Z",
     "shell.execute_reply": "2021-04-10T17:17:55.093045Z",
     "shell.execute_reply.started": "2021-04-10T17:17:55.079448Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set([stemmer.stem(w) for w in no_emb]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "996d4a35",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-10T13:58:16.483560Z",
     "iopub.status.busy": "2021-04-10T13:58:16.483100Z",
     "iopub.status.idle": "2021-04-10T13:58:16.829888Z",
     "shell.execute_reply": "2021-04-10T13:58:16.829436Z",
     "shell.execute_reply.started": "2021-04-10T13:58:16.483502Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "167999c53df4487c9f698aa5196ae364",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "no_embeddings = []\n",
    "for sentence in tqdm(sentences):\n",
    "    sentence = preprocess(sentence)\n",
    "    for tk in re.split(' +', sentence):\n",
    "        if tk not in word_vectors:\n",
    "            no_embeddings.append(tk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d26d14f",
   "metadata": {},
   "source": [
    "# Dataset class using GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "e2fdddcc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-10T16:19:12.265730Z",
     "iopub.status.busy": "2021-04-10T16:19:12.265565Z",
     "iopub.status.idle": "2021-04-10T16:19:12.271147Z",
     "shell.execute_reply": "2021-04-10T16:19:12.270537Z",
     "shell.execute_reply.started": "2021-04-10T16:19:12.265710Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class WiCDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset_path: str):\n",
    "        self.data = []\n",
    "        self.create_dataset(dataset_path)\n",
    "        \n",
    "    \n",
    "    def create_dataset(self, dataset_path: str) -> None:\n",
    "        with jsonlines.open(dataset_path, 'r') as f:\n",
    "            for i, line in enumerate(f.iter()):\n",
    "                start1 = int(line['start1'])\n",
    "                start2 = int(line['start2'])\n",
    "                s1 = w_sentence2vector(preprocess(line['sentence1']), start1)\n",
    "                s2 = w_sentence2vector(preprocess(line['sentence2']), start2)\n",
    "                # s1 = sentence2vector(line['sentence1'])\n",
    "                # s2 = sentence2vector(line['sentence2'])\n",
    "                \n",
    "                # sentence = f\"{line['sentence1']} {line['sentence2']}\"\n",
    "                sentence_vector = torch.cat((s1, s2))\n",
    "                \n",
    "                label = torch.tensor(1, dtype=torch.float32) if line['label'] == 'True' else torch.tensor(0, dtype=torch.float32)\n",
    "                self.data.append((sentence_vector, label))\n",
    "\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> torch.Tensor:\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2434d35f",
   "metadata": {},
   "source": [
    "# Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "29cf8a49",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-10T10:58:38.099599Z",
     "iopub.status.busy": "2021-04-10T10:58:38.099124Z",
     "iopub.status.idle": "2021-04-10T10:58:38.111887Z",
     "shell.execute_reply": "2021-04-10T10:58:38.110790Z",
     "shell.execute_reply.started": "2021-04-10T10:58:38.099540Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_features: int,\n",
    "        num_layers: int,\n",
    "        hidden_dim: int,\n",
    "        activation: Callable[[torch.Tensor], torch.Tensor],\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.first_layer = nn.Linear(in_features=n_features, out_features=hidden_dim)\n",
    "\n",
    "        self.layers = (\n",
    "            nn.ModuleList()\n",
    "        )\n",
    "\n",
    "        for i in range(num_layers):\n",
    "            self.layers.append(\n",
    "                nn.Linear(in_features=hidden_dim, out_features=hidden_dim)\n",
    "            )\n",
    "        self.activation = activation\n",
    "        \n",
    "        self.batchnorm = nn.BatchNorm1d(hidden_dim)\n",
    "\n",
    "        self.last_layer = nn.Linear(in_features=hidden_dim, out_features=1)\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, meshgrid: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Applies transformations to each (x, y) independently\n",
    "\n",
    "        :param meshgrid: tensor of dimensions [..., 2], where ... means any number of dims\n",
    "        \"\"\"\n",
    "        out = meshgrid\n",
    "\n",
    "        out = self.first_layer(\n",
    "            out\n",
    "        )  # First linear layer, transforms the hidden dimensions from `n_features` (embedding dimension) to `hidden_dim`\n",
    "        for layer in self.layers:  # Apply `k` (linear, activation) layer\n",
    "            out = layer(out)\n",
    "            out = self.activation(out)\n",
    "            # out = self.batchnorm(out)\n",
    "            # out = nn.Dropout(p=0.2)(out)\n",
    "        out = self.last_layer(\n",
    "            out\n",
    "        )  # Last linear layer to bring the `hiddem_dim` features to a binary space (`True`/`False`)\n",
    "        \n",
    "        out = self.sigmoid(out)\n",
    "        return out.squeeze(-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84e4d8d",
   "metadata": {},
   "source": [
    "# Training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "b0293473",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-10T16:17:30.391856Z",
     "iopub.status.busy": "2021-04-10T16:17:30.391689Z",
     "iopub.status.idle": "2021-04-10T16:17:30.399555Z",
     "shell.execute_reply": "2021-04-10T16:17:30.398690Z",
     "shell.execute_reply.started": "2021-04-10T16:17:30.391835Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def correctly_predicted(predicted, gt):\n",
    "    predicted_labels = (predicted > 0.5).float()\n",
    "\n",
    "    return (predicted_labels == gt).sum().item(), gt.shape[0]\n",
    "\n",
    "def step(model, criterion, xb, yb, opt=None):\n",
    "    loss = criterion(model(xb), yb)\n",
    "\n",
    "    if opt is not None:\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "    return loss.item(), len(xb)\n",
    "\n",
    "\n",
    "def fit(epochs, model, criterion, opt, train_dl, valid_dl, checkpoint=None):\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        model.train()\n",
    "        for xb, yb in train_dl:\n",
    "            xb = xb.to(device)\n",
    "            yb = yb.to(device)\n",
    "            step(model, criterion, xb, yb, opt)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            # losses, nums = zip(*[step(model, criterion, xb, yb) for xb, yb in valid_dl])\n",
    "            losses = []\n",
    "            nums = []\n",
    "            corrects = []\n",
    "            for xb, yb in valid_dl:\n",
    "                xb = xb.to(device)\n",
    "                yb = yb.to(device)\n",
    "                \n",
    "                loss, num = step(model, criterion, xb, yb)\n",
    "                correct, _ = correctly_predicted(model(xb), yb)\n",
    "                losses.append(loss)\n",
    "                nums.append(num)\n",
    "                corrects.append(correct)\n",
    "                \n",
    "        # val_loss = np.sum(losses) / np.sum(nums)\n",
    "        \n",
    "        val_loss = np.sum(np.multiply(losses, nums)) / np.sum(nums)\n",
    "        val_acc = np.sum(corrects) / np.sum(nums)\n",
    "\n",
    "        if checkpoint:\n",
    "            checkpoint.save(model, opt, epoch, val_loss, val_acc)\n",
    "\n",
    "        print(f\"{epoch} \\t {val_loss:.2f} \\t {val_acc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "9cd31302",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-10T16:19:17.450174Z",
     "iopub.status.busy": "2021-04-10T16:19:17.450004Z",
     "iopub.status.idle": "2021-04-10T16:19:21.443275Z",
     "shell.execute_reply": "2021-04-10T16:19:21.442597Z",
     "shell.execute_reply.started": "2021-04-10T16:19:17.450154Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = WiCDataset(train_path)\n",
    "val_dataset = WiCDataset(dev_path)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "911db799",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-10T16:19:21.444177Z",
     "iopub.status.busy": "2021-04-10T16:19:21.444033Z",
     "iopub.status.idle": "2021-04-10T16:19:21.454723Z",
     "shell.execute_reply": "2021-04-10T16:19:21.454131Z",
     "shell.execute_reply.started": "2021-04-10T16:19:21.444157Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "criterion = nn.BCELoss()#.to(device)\n",
    "model = MLP(n_features=600,\n",
    "            num_layers=5, \n",
    "            hidden_dim=150, \n",
    "            activation=torch.nn.functional.relu).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, weight_decay=0.00001)\n",
    "\n",
    "checkpoint = Checkpoint(path='checkpoints')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "567d542d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-10T16:19:21.456081Z",
     "iopub.status.busy": "2021-04-10T16:19:21.455855Z",
     "iopub.status.idle": "2021-04-10T16:20:01.191779Z",
     "shell.execute_reply": "2021-04-10T16:20:01.191022Z",
     "shell.execute_reply.started": "2021-04-10T16:19:21.456055Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6462a4d92b094dbc96acd851581dd62e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/150 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \t 0.69 \t 0.5\n",
      "1 \t 0.69 \t 0.521\n",
      "2 \t 0.69 \t 0.523\n",
      "3 \t 0.69 \t 0.545\n",
      "4 \t 0.69 \t 0.531\n",
      "5 \t 0.68 \t 0.565\n",
      "6 \t 0.68 \t 0.547\n",
      "7 \t 0.68 \t 0.56\n",
      "8 \t 0.68 \t 0.581\n",
      "9 \t 0.68 \t 0.581\n",
      "10 \t 0.67 \t 0.574\n",
      "11 \t 0.67 \t 0.593\n",
      "12 \t 0.66 \t 0.604\n",
      "13 \t 0.66 \t 0.601\n",
      "14 \t 0.66 \t 0.609\n",
      "15 \t 0.66 \t 0.614\n",
      "16 \t 0.66 \t 0.624\n",
      "17 \t 0.66 \t 0.626\n",
      "18 \t 0.69 \t 0.609\n",
      "19 \t 0.69 \t 0.621\n",
      "20 \t 0.73 \t 0.609\n",
      "21 \t 0.73 \t 0.616\n",
      "22 \t 0.77 \t 0.601\n",
      "23 \t 0.79 \t 0.61\n",
      "24 \t 0.83 \t 0.611\n",
      "25 \t 0.86 \t 0.592\n",
      "26 \t 0.90 \t 0.6\n",
      "27 \t 0.93 \t 0.607\n",
      "28 \t 1.00 \t 0.595\n",
      "29 \t 1.04 \t 0.611\n",
      "30 \t 1.11 \t 0.591\n",
      "31 \t 1.16 \t 0.605\n",
      "32 \t 1.19 \t 0.587\n",
      "33 \t 1.26 \t 0.597\n",
      "34 \t 1.35 \t 0.596\n",
      "35 \t 1.40 \t 0.601\n",
      "36 \t 1.44 \t 0.606\n",
      "37 \t 1.54 \t 0.605\n",
      "38 \t 1.58 \t 0.596\n",
      "39 \t 1.62 \t 0.61\n",
      "40 \t 1.70 \t 0.601\n",
      "41 \t 1.77 \t 0.594\n",
      "42 \t 1.88 \t 0.598\n",
      "43 \t 1.90 \t 0.596\n",
      "44 \t 1.95 \t 0.603\n",
      "45 \t 2.04 \t 0.609\n",
      "46 \t 2.04 \t 0.592\n",
      "47 \t 2.11 \t 0.597\n",
      "48 \t 2.25 \t 0.592\n",
      "49 \t 2.28 \t 0.594\n",
      "50 \t 2.33 \t 0.6\n",
      "51 \t 2.35 \t 0.6\n",
      "52 \t 2.68 \t 0.593\n",
      "53 \t 2.55 \t 0.594\n",
      "54 \t 2.56 \t 0.596\n",
      "55 \t 3.15 \t 0.579\n",
      "56 \t 1.69 \t 0.597\n",
      "57 \t 2.06 \t 0.601\n",
      "58 \t 2.01 \t 0.605\n",
      "59 \t 2.27 \t 0.609\n",
      "60 \t 2.31 \t 0.609\n",
      "61 \t 2.47 \t 0.609\n",
      "62 \t 2.60 \t 0.609\n",
      "63 \t 2.66 \t 0.609\n",
      "64 \t 2.69 \t 0.606\n",
      "65 \t 2.74 \t 0.608\n",
      "66 \t 2.74 \t 0.604\n",
      "67 \t 2.79 \t 0.615\n",
      "68 \t 2.84 \t 0.61\n",
      "69 \t 3.05 \t 0.61\n",
      "70 \t 3.16 \t 0.609\n",
      "71 \t 3.38 \t 0.607\n",
      "72 \t 3.71 \t 0.608\n",
      "73 \t 3.98 \t 0.61\n",
      "74 \t 4.31 \t 0.609\n",
      "75 \t 4.45 \t 0.608\n",
      "76 \t 4.50 \t 0.608\n",
      "77 \t 4.63 \t 0.61\n",
      "78 \t 4.83 \t 0.607\n",
      "79 \t 4.86 \t 0.609\n",
      "80 \t 5.06 \t 0.607\n",
      "81 \t 5.09 \t 0.609\n",
      "82 \t 5.20 \t 0.608\n",
      "83 \t 5.31 \t 0.609\n",
      "84 \t 5.33 \t 0.609\n",
      "85 \t 5.44 \t 0.607\n",
      "86 \t 5.46 \t 0.609\n",
      "87 \t 5.57 \t 0.609\n",
      "88 \t 5.59 \t 0.609\n",
      "89 \t 5.61 \t 0.608\n",
      "90 \t 5.64 \t 0.609\n",
      "91 \t 5.66 \t 0.608\n",
      "92 \t 5.69 \t 0.608\n",
      "93 \t 5.72 \t 0.608\n",
      "94 \t 5.74 \t 0.606\n",
      "95 \t 5.77 \t 0.607\n",
      "96 \t 5.79 \t 0.607\n",
      "97 \t 5.80 \t 0.609\n",
      "98 \t 5.82 \t 0.606\n",
      "99 \t 6.08 \t 0.608\n",
      "100 \t 6.01 \t 0.607\n",
      "101 \t 6.10 \t 0.606\n",
      "102 \t 6.11 \t 0.606\n",
      "103 \t 6.12 \t 0.607\n",
      "104 \t 6.13 \t 0.607\n",
      "105 \t 6.13 \t 0.606\n",
      "106 \t 6.22 \t 0.606\n",
      "107 \t 6.14 \t 0.606\n",
      "108 \t 6.40 \t 0.605\n",
      "109 \t 6.41 \t 0.605\n",
      "110 \t 6.59 \t 0.606\n",
      "111 \t 6.61 \t 0.604\n",
      "112 \t 6.63 \t 0.604\n",
      "113 \t 6.64 \t 0.605\n",
      "114 \t 6.74 \t 0.604\n",
      "115 \t 6.92 \t 0.605\n",
      "116 \t 6.85 \t 0.605\n",
      "117 \t 6.95 \t 0.605\n",
      "118 \t 6.96 \t 0.605\n",
      "119 \t 7.05 \t 0.604\n",
      "120 \t 7.14 \t 0.604\n",
      "121 \t 7.07 \t 0.604\n",
      "122 \t 7.24 \t 0.604\n",
      "123 \t 7.08 \t 0.604\n",
      "124 \t 7.16 \t 0.604\n",
      "125 \t 7.09 \t 0.605\n",
      "126 \t 7.09 \t 0.604\n",
      "127 \t 7.01 \t 0.605\n",
      "128 \t 7.01 \t 0.605\n",
      "129 \t 7.02 \t 0.605\n",
      "130 \t 7.02 \t 0.605\n",
      "131 \t 7.10 \t 0.604\n",
      "132 \t 7.10 \t 0.604\n",
      "133 \t 6.94 \t 0.605\n",
      "134 \t 7.19 \t 0.604\n",
      "135 \t 6.94 \t 0.605\n",
      "136 \t 7.11 \t 0.604\n",
      "137 \t 6.95 \t 0.608\n",
      "138 \t 6.95 \t 0.607\n",
      "139 \t 6.95 \t 0.604\n",
      "140 \t 6.95 \t 0.605\n",
      "141 \t 7.03 \t 0.604\n",
      "142 \t 6.95 \t 0.605\n",
      "143 \t 6.95 \t 0.605\n",
      "144 \t 6.96 \t 0.605\n",
      "145 \t 6.96 \t 0.605\n",
      "146 \t 6.87 \t 0.605\n",
      "147 \t 6.96 \t 0.605\n",
      "148 \t 6.87 \t 0.607\n",
      "149 \t 6.96 \t 0.605\n"
     ]
    }
   ],
   "source": [
    "fit(150, model, criterion, optimizer, train_loader, val_loader, checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9e375480",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-09T22:47:48.050612Z",
     "iopub.status.busy": "2021-04-09T22:47:48.050443Z",
     "iopub.status.idle": "2021-04-09T22:47:59.327396Z",
     "shell.execute_reply": "2021-04-09T22:47:59.326771Z",
     "shell.execute_reply.started": "2021-04-09T22:47:48.050592Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65fc8c5c9f504330b28a4719ecd74a95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \t 0.69 \t 0.5\n",
      "1 \t 0.69 \t 0.5\n",
      "2 \t 0.69 \t 0.5\n",
      "3 \t 0.69 \t 0.521\n",
      "4 \t 0.69 \t 0.551\n",
      "5 \t 0.68 \t 0.552\n",
      "6 \t 0.68 \t 0.552\n",
      "7 \t 0.68 \t 0.546\n",
      "8 \t 0.68 \t 0.559\n",
      "9 \t 0.69 \t 0.563\n",
      "10 \t 0.68 \t 0.573\n",
      "11 \t 0.68 \t 0.58\n",
      "12 \t 0.68 \t 0.569\n",
      "13 \t 0.67 \t 0.584\n",
      "14 \t 0.69 \t 0.59\n",
      "15 \t 0.67 \t 0.598\n",
      "16 \t 0.67 \t 0.591\n",
      "17 \t 0.67 \t 0.602\n",
      "18 \t 0.68 \t 0.604\n",
      "19 \t 0.70 \t 0.595\n",
      "20 \t 0.71 \t 0.606\n",
      "21 \t 0.72 \t 0.609\n",
      "22 \t 0.73 \t 0.607\n",
      "23 \t 0.79 \t 0.585\n",
      "24 \t 0.77 \t 0.608\n",
      "25 \t 0.82 \t 0.596\n",
      "26 \t 0.85 \t 0.609\n",
      "27 \t 0.88 \t 0.583\n",
      "28 \t 0.91 \t 0.597\n",
      "29 \t 0.97 \t 0.586\n",
      "30 \t 1.00 \t 0.589\n",
      "31 \t 1.09 \t 0.589\n",
      "32 \t 1.14 \t 0.605\n",
      "33 \t 1.19 \t 0.614\n",
      "34 \t 1.26 \t 0.596\n",
      "35 \t 1.32 \t 0.602\n",
      "36 \t 1.42 \t 0.608\n",
      "37 \t 1.48 \t 0.589\n",
      "38 \t 1.62 \t 0.597\n",
      "39 \t 1.68 \t 0.594\n",
      "40 \t 1.75 \t 0.596\n",
      "41 \t 1.81 \t 0.603\n",
      "42 \t 1.90 \t 0.596\n",
      "43 \t 1.98 \t 0.594\n",
      "44 \t 2.04 \t 0.596\n",
      "45 \t 2.11 \t 0.601\n",
      "46 \t 2.23 \t 0.596\n",
      "47 \t 2.37 \t 0.6\n",
      "48 \t 2.44 \t 0.601\n",
      "49 \t 2.58 \t 0.602\n"
     ]
    }
   ],
   "source": [
    "fit(50, model, criterion, optimizer, train_loader, val_loader, checkpoint)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
