{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7b169159",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-09T13:08:30.656376Z",
     "iopub.status.busy": "2021-04-09T13:08:30.656013Z",
     "iopub.status.idle": "2021-04-09T13:08:30.662232Z",
     "shell.execute_reply": "2021-04-09T13:08:30.661531Z",
     "shell.execute_reply.started": "2021-04-09T13:08:30.656330Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from pprint import pprint\n",
    "import jsonlines\n",
    "import os\n",
    "import re\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "\n",
    "from typing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ff11b7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-09T12:56:42.671709Z",
     "iopub.status.busy": "2021-04-09T12:56:42.671584Z",
     "iopub.status.idle": "2021-04-09T12:56:42.673924Z",
     "shell.execute_reply": "2021-04-09T12:56:42.673441Z",
     "shell.execute_reply.started": "2021-04-09T12:56:42.671693Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_path = 'data/train.jsonl'\n",
    "dev_path = 'data/dev.jsonl'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798b6769",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55a5b6c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-09T12:56:47.685753Z",
     "iopub.status.busy": "2021-04-09T12:56:47.685557Z",
     "iopub.status.idle": "2021-04-09T12:56:47.689441Z",
     "shell.execute_reply": "2021-04-09T12:56:47.688863Z",
     "shell.execute_reply.started": "2021-04-09T12:56:47.685736Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_dictionary(dictionary, path):\n",
    "    with open(path, 'wb') as f:\n",
    "        pickle.dump(dictionary, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_dictionary(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "75c5b4b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-09T13:11:16.321987Z",
     "iopub.status.busy": "2021-04-09T13:11:16.321603Z",
     "iopub.status.idle": "2021-04-09T13:11:16.335669Z",
     "shell.execute_reply": "2021-04-09T13:11:16.334771Z",
     "shell.execute_reply.started": "2021-04-09T13:11:16.321939Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Saving / loading models\n",
    "class Checkpoint:\n",
    "    def __init__(self, path, resume=False):\n",
    "        self.path = path\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "        self.resume = resume\n",
    "\n",
    "    def load(self, model, optimizer, id_path=\"\"):\n",
    "        if (not self.resume) and id_path == \"\":\n",
    "            raise RuntimeError()\n",
    "        if self.resume:\n",
    "            id_path = sorted(os.listdir(self.path))[-1]\n",
    "        self.checkpoint = torch.load(\n",
    "            os.path.join(self.path, id_path), map_location=lambda storage, loc: storage\n",
    "        )\n",
    "        if self.checkpoint == None:\n",
    "            raise RuntimeError(\"Checkpoint empty.\")\n",
    "        epoch = self.checkpoint[\"epoch\"]\n",
    "        model.load_state_dict(self.checkpoint[\"model_state_dict\"])\n",
    "        optimizer.load_state_dict(self.checkpoint[\"optimizer_state_dict\"])\n",
    "        loss = self.checkpoint[\"loss\"]\n",
    "        return (model, optimizer, epoch, loss)\n",
    "\n",
    "    def save(self, model, optimizer, epoch, loss, accuracy):\n",
    "        model_checkpoint = {\n",
    "            \"model_state_dict\": model.state_dict(),\n",
    "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "            \"epoch\": epoch,\n",
    "            \"loss\": loss,\n",
    "            \"accuracy\": accuracy\n",
    "        }\n",
    "        checkpoint_name = \"{}.pth\".format(str(epoch).zfill(3))\n",
    "        complete_path = os.path.join(self.path, checkpoint_name)\n",
    "        torch.save(model_checkpoint, complete_path)\n",
    "        return checkpoint_name\n",
    "\n",
    "    def load_just_model(self, model, id_path=\"\"):\n",
    "        if self.resume:\n",
    "            id_path = sorted(os.listdir(self.path))[-1]\n",
    "        self.checkpoint = torch.load(\n",
    "            os.path.join(self.path, id_path), map_location=lambda storage, loc: storage\n",
    "        )\n",
    "        if self.checkpoint == None:\n",
    "            raise RuntimeError(\"Checkpoint empty.\")\n",
    "        model.load_state_dict(self.checkpoint[\"model_state_dict\"])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab45ac85",
   "metadata": {},
   "source": [
    "# Create word embedding with GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b3b6b2e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-09T12:56:48.230087Z",
     "iopub.status.busy": "2021-04-09T12:56:48.229927Z",
     "iopub.status.idle": "2021-04-09T12:56:48.233861Z",
     "shell.execute_reply": "2021-04-09T12:56:48.233210Z",
     "shell.execute_reply.started": "2021-04-09T12:56:48.230069Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sentence2vector(sentence: str) -> Optional[torch.Tensor]:\n",
    "    sentences_word_vector = [word_vectors[w] for w in sentence.split(' ') if w in word_vectors]\n",
    "    \n",
    "    if len(sentences_word_vector) == 0:\n",
    "        return None\n",
    "\n",
    "    sentences_word_vector = torch.stack(sentences_word_vector)  # tensor shape: (#words X #features)\n",
    "    return torch.mean(sentences_word_vector, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09e35c9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-09T12:56:48.747669Z",
     "iopub.status.busy": "2021-04-09T12:56:48.747216Z",
     "iopub.status.idle": "2021-04-09T12:56:48.753408Z",
     "shell.execute_reply": "2021-04-09T12:56:48.752785Z",
     "shell.execute_reply.started": "2021-04-09T12:56:48.747614Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cosine_similarity(v1: torch.Tensor, v2: torch.Tensor) -> float:\n",
    "    num = torch.sum(v1 * v2)\n",
    "    den = torch.linalg.norm(v1) * torch.linalg.norm(v2)\n",
    "    return (num / den).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca03eb4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-09T12:56:49.107384Z",
     "iopub.status.busy": "2021-04-09T12:56:49.107077Z",
     "iopub.status.idle": "2021-04-09T12:57:21.952928Z",
     "shell.execute_reply": "2021-04-09T12:57:21.952478Z",
     "shell.execute_reply.started": "2021-04-09T12:56:49.107343Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50feed3d6cb44f8fa7ac1a47c64d4f7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "word_vectors = dict()\n",
    "n_words = 400_000\n",
    "with open('embeddings/glove.6B.300d.txt') as f:\n",
    "    for i, line in tqdm(enumerate(f), total=n_words):\n",
    "\n",
    "        word, *vector = line.strip().split(' ')\n",
    "        vector = torch.tensor([float(c) for c in vector])\n",
    "        \n",
    "        word_vectors[word] = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3eabd508",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-09T13:23:58.035928Z",
     "iopub.status.busy": "2021-04-09T13:23:58.035659Z",
     "iopub.status.idle": "2021-04-09T13:24:17.643624Z",
     "shell.execute_reply": "2021-04-09T13:24:17.643100Z",
     "shell.execute_reply.started": "2021-04-09T13:23:58.035895Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "save_dictionary(word_vectors, 'vocabulary.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0259cf0f",
   "metadata": {},
   "source": [
    "# Dataset class using GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89353027",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-09T13:06:06.524091Z",
     "iopub.status.busy": "2021-04-09T13:06:06.523675Z",
     "iopub.status.idle": "2021-04-09T13:06:06.533331Z",
     "shell.execute_reply": "2021-04-09T13:06:06.532651Z",
     "shell.execute_reply.started": "2021-04-09T13:06:06.524016Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class WiCDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset_path: str):\n",
    "        self.data = []\n",
    "        self.create_dataset(dataset_path)\n",
    "    \n",
    "    def create_dataset(self, dataset_path: str) -> None:\n",
    "        with jsonlines.open(dataset_path, 'r') as f:\n",
    "            for i, line in enumerate(f.iter()):\n",
    "                s1 = sentence2vector(line['sentence1'])\n",
    "                s2 = sentence2vector(line['sentence2'])\n",
    "                # sentence = f\"{line['sentence1']} {line['sentence2']}\"\n",
    "                sentence_vector = torch.cat((s1, s2))\n",
    "                \n",
    "                label = torch.tensor(1, dtype=torch.float32) if line['label'] == 'True' else torch.tensor(0, dtype=torch.float32)\n",
    "                self.data.append((sentence_vector, label))\n",
    "\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> torch.Tensor:\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb7e37c",
   "metadata": {},
   "source": [
    "# Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "743d5dbb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-09T12:58:27.437632Z",
     "iopub.status.busy": "2021-04-09T12:58:27.436997Z",
     "iopub.status.idle": "2021-04-09T12:58:27.446379Z",
     "shell.execute_reply": "2021-04-09T12:58:27.445774Z",
     "shell.execute_reply.started": "2021-04-09T12:58:27.437553Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_features: int,\n",
    "        num_layers: int,\n",
    "        hidden_dim: int,\n",
    "        activation: Callable[[torch.Tensor], torch.Tensor],\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.first_layer = nn.Linear(in_features=n_features, out_features=hidden_dim)\n",
    "\n",
    "        self.layers = (\n",
    "            nn.ModuleList()\n",
    "        )\n",
    "\n",
    "        for i in range(num_layers):\n",
    "            self.layers.append(\n",
    "                nn.Linear(in_features=hidden_dim, out_features=hidden_dim)\n",
    "            )\n",
    "        self.activation = activation\n",
    "        \n",
    "        self.batchnorm = nn.BatchNorm1d(hidden_dim)\n",
    "\n",
    "        self.last_layer = nn.Linear(in_features=hidden_dim, out_features=1)\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, meshgrid: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Applies transformations to each (x, y) independently\n",
    "\n",
    "        :param meshgrid: tensor of dimensions [..., 2], where ... means any number of dims\n",
    "        \"\"\"\n",
    "        out = meshgrid\n",
    "\n",
    "        out = self.first_layer(\n",
    "            out\n",
    "        )  # First linear layer, transforms the hidden dimensions from `n_features` (embedding dimension) to `hidden_dim`\n",
    "        for layer in self.layers:  # Apply `k` (linear, activation) layer\n",
    "            out = layer(out)\n",
    "            out = self.activation(out)\n",
    "            # out = self.batchnorm(out)\n",
    "            # out = nn.Dropout(p=0.2)(out)\n",
    "        out = self.last_layer(\n",
    "            out\n",
    "        )  # Last linear layer to bring the `hiddem_dim` features to a binary space (`True`/`False`)\n",
    "        \n",
    "        out = self.sigmoid(out)\n",
    "        return out.squeeze(-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e7a37d",
   "metadata": {},
   "source": [
    "# Training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "42b6f0ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-09T13:11:25.633897Z",
     "iopub.status.busy": "2021-04-09T13:11:25.633169Z",
     "iopub.status.idle": "2021-04-09T13:11:25.646837Z",
     "shell.execute_reply": "2021-04-09T13:11:25.646037Z",
     "shell.execute_reply.started": "2021-04-09T13:11:25.633812Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def correctly_predicted(predicted, gt):\n",
    "    predicted_labels = (predicted > 0.5).float()\n",
    "\n",
    "    return (predicted_labels == gt).sum().item(), gt.shape[0]\n",
    "\n",
    "def step(model, criterion, xb, yb, opt=None):\n",
    "    loss = criterion(model(xb), yb)\n",
    "\n",
    "    if opt is not None:\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "    return loss.item(), len(xb)\n",
    "\n",
    "\n",
    "def fit(epochs, model, criterion, opt, train_dl, valid_dl, checkpoint=None):\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        model.train()\n",
    "        for xb, yb in train_dl:\n",
    "            xb = xb.to(device)\n",
    "            yb = yb.to(device)\n",
    "            step(model, criterion, xb, yb, opt)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            # losses, nums = zip(*[step(model, criterion, xb, yb) for xb, yb in valid_dl])\n",
    "            losses = []\n",
    "            nums = []\n",
    "            corrects = []\n",
    "            for xb, yb in valid_dl:\n",
    "                xb = xb.to(device)\n",
    "                yb = yb.to(device)\n",
    "                \n",
    "                loss, num = step(model, criterion, xb, yb)\n",
    "                correct, _ = correctly_predicted(model(xb), yb)\n",
    "                losses.append(loss)\n",
    "                nums.append(num)\n",
    "                corrects.append(correct)\n",
    "                \n",
    "\n",
    "        val_loss = np.sum(np.multiply(losses, nums)) / np.sum(nums)\n",
    "        val_acc = np.sum(corrects) / np.sum(nums)\n",
    "\n",
    "        if checkpoint:\n",
    "            checkpoint.save(model, opt, epoch, val_loss, val_acc)\n",
    "\n",
    "        print(f\"{epoch} \\t {val_loss:.2f} \\t {val_acc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fde4c1ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-09T13:06:11.186145Z",
     "iopub.status.busy": "2021-04-09T13:06:11.185710Z",
     "iopub.status.idle": "2021-04-09T13:06:12.356028Z",
     "shell.execute_reply": "2021-04-09T13:06:12.355626Z",
     "shell.execute_reply.started": "2021-04-09T13:06:11.186098Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = WiCDataset(train_path)\n",
    "val_dataset = WiCDataset(dev_path)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "96adfb1f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-09T13:13:39.063127Z",
     "iopub.status.busy": "2021-04-09T13:13:39.062825Z",
     "iopub.status.idle": "2021-04-09T13:13:39.076397Z",
     "shell.execute_reply": "2021-04-09T13:13:39.075831Z",
     "shell.execute_reply.started": "2021-04-09T13:13:39.063096Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "criterion = nn.BCELoss()#.to(device)\n",
    "model = MLP(n_features=600,\n",
    "            num_layers=5, \n",
    "            hidden_dim=150, \n",
    "            activation=torch.nn.functional.relu).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, weight_decay=0.00001)\n",
    "\n",
    "checkpoint = Checkpoint(path='checkpoints')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8af7ae88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-09T13:13:39.096664Z",
     "iopub.status.busy": "2021-04-09T13:13:39.096488Z",
     "iopub.status.idle": "2021-04-09T13:14:03.085708Z",
     "shell.execute_reply": "2021-04-09T13:14:03.085062Z",
     "shell.execute_reply.started": "2021-04-09T13:13:39.096645Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d91b297f65c4dd185320c1631b00be8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \t 0.69 \t 0.5\n",
      "1 \t 0.69 \t 0.501\n",
      "2 \t 0.69 \t 0.55\n",
      "3 \t 0.69 \t 0.565\n",
      "4 \t 0.68 \t 0.56\n",
      "5 \t 0.67 \t 0.576\n",
      "6 \t 0.67 \t 0.58\n",
      "7 \t 0.66 \t 0.614\n",
      "8 \t 0.67 \t 0.597\n",
      "9 \t 0.65 \t 0.617\n",
      "10 \t 0.66 \t 0.605\n",
      "11 \t 0.66 \t 0.617\n",
      "12 \t 0.67 \t 0.622\n",
      "13 \t 0.66 \t 0.628\n",
      "14 \t 0.69 \t 0.612\n",
      "15 \t 0.70 \t 0.628\n",
      "16 \t 0.71 \t 0.623\n",
      "17 \t 0.77 \t 0.609\n",
      "18 \t 0.76 \t 0.621\n",
      "19 \t 0.81 \t 0.622\n",
      "20 \t 0.87 \t 0.605\n",
      "21 \t 0.86 \t 0.634\n",
      "22 \t 0.91 \t 0.629\n",
      "23 \t 0.96 \t 0.617\n",
      "24 \t 1.06 \t 0.61\n",
      "25 \t 1.12 \t 0.619\n",
      "26 \t 1.20 \t 0.6\n",
      "27 \t 1.21 \t 0.617\n",
      "28 \t 1.28 \t 0.608\n",
      "29 \t 1.36 \t 0.609\n",
      "30 \t 1.49 \t 0.594\n",
      "31 \t 1.50 \t 0.616\n",
      "32 \t 1.63 \t 0.591\n",
      "33 \t 1.71 \t 0.598\n",
      "34 \t 1.66 \t 0.613\n",
      "35 \t 1.84 \t 0.602\n",
      "36 \t 1.85 \t 0.591\n",
      "37 \t 2.02 \t 0.59\n",
      "38 \t 2.29 \t 0.597\n",
      "39 \t 2.38 \t 0.6\n",
      "40 \t 2.65 \t 0.612\n",
      "41 \t 2.23 \t 0.59\n",
      "42 \t 2.37 \t 0.587\n",
      "43 \t 2.38 \t 0.597\n",
      "44 \t 2.51 \t 0.593\n",
      "45 \t 2.64 \t 0.587\n",
      "46 \t 2.97 \t 0.596\n",
      "47 \t 2.86 \t 0.592\n",
      "48 \t 3.10 \t 0.589\n",
      "49 \t 3.14 \t 0.596\n"
     ]
    }
   ],
   "source": [
    "fit(50, model, criterion, optimizer, train_loader, val_loader, checkpoint)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
